{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# integrate.ai API Sample Notebook to run server on AWS Fargate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set environment variables (or replace inline) with your IAI credentials\n",
    "### Generate and manage this token in the UI, in the Tokens page\n",
    "### Generate AWS session credentials or use the default profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "get access token"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "IAI_TOKEN = os.environ.get(\"IAI_TOKEN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authenticate to the integrate.ai api client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "authenticate to client"
    ]
   },
   "outputs": [],
   "source": [
    "from integrate_ai_sdk.api import connect\n",
    "\n",
    "client = connect(token=IAI_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample model config and data schema\n",
    "You can find the model config and data schema in the [integrate.ai end user tutorial](https://integrate-ai.gitbook.io/integrate.ai-user-documentation/tutorials/end-user-tutorials/model-training-with-a-sample-local-dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "assign schemas"
    ]
   },
   "outputs": [],
   "source": [
    "model_config = {\n",
    "    \"experiment_name\": \"test_notebook_glm_external_fargate\",\n",
    "    \"experiment_description\": \"test_notebook_glm_external_fargate\",\n",
    "    \"strategy\": {\"name\": \"FedAvg\", \"params\": {}},\n",
    "    \"model\": {\n",
    "        \"params\": {\"input_size\": 15, \"output_activation\": \"sigmoid\"},\n",
    "    },\n",
    "    \"balance_train_datasets\": False,\n",
    "    \"ml_task\": {\n",
    "        \"type\": \"logistic\",\n",
    "        \"params\": {\n",
    "            \"loss_weights\": None,\n",
    "        },\n",
    "    },\n",
    "    \"optimizer\": {\"name\": \"SGD\", \"params\": {\"learning_rate\": 0.2, \"momentum\": 0.0}},\n",
    "    \"differential_privacy_params\": {\"epsilon\": 4, \"max_grad_norm\": 7},\n",
    "    \"save_best_model\": {\n",
    "        \"metric\": \"loss\",  # to disable this and save model from the last round, set to None\n",
    "        \"mode\": \"min\",\n",
    "    },\n",
    "    \"seed\": 23,  # for reproducibility\n",
    "}\n",
    "\n",
    "data_schema = {\n",
    "    \"predictors\": [\"x0\", \"x1\", \"x2\", \"x3\", \"x4\", \"x5\", \"x6\", \"x7\", \"x8\", \"x9\", \"x10\", \"x11\", \"x12\", \"x13\", \"x14\"],\n",
    "    \"target\": \"y\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Training Session\n",
    "\n",
    "The documentation for [creating a session](https://integrate-ai.gitbook.io/integrate.ai-user-documentation/tutorials/end-user-tutorials/model-training-with-a-sample-local-dataset#create-and-start-the-session) gives a bit more context into the parameters that are used during training session creation.<br />\n",
    "For this session we are going to be using two training clients and two rounds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "start session"
    ]
   },
   "outputs": [],
   "source": [
    "training_session = client.create_fl_session(\n",
    "    name=\"Testing notebook\",\n",
    "    description=\"I am testing session creation through a notebook\",\n",
    "    min_num_clients=2,\n",
    "    num_rounds=2,\n",
    "    package_name=\"iai_glm\",\n",
    "    model_config=model_config,\n",
    "    data_config=data_schema,\n",
    "    startup_mode=\"external\",\n",
    ").start()\n",
    "\n",
    "training_session.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Run Training Server on AWS Fargate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specifying optional AWS Credentials, Cluster, Task Definition Name and Network Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "set aws vars"
    ]
   },
   "outputs": [],
   "source": [
    "# Set your AWS Credentials if you are generating temporary ones, else use the default profile credentials\n",
    "aws_creds = {\n",
    "    \"ACCESS_KEY\": os.environ.get(\"AWS_ACCESS_KEY_ID\"),\n",
    "    \"SECRET_KEY\": os.environ.get(\"AWS_SECRET_ACCESS_KEY\"),\n",
    "    \"SESSION_TOKEN\": os.environ.get(\"AWS_SESSION_TOKEN\"),\n",
    "    \"REGION\": os.environ.get(\"AWS_REGION\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the name of your cluster, task definition, network parameters, and batch job definitions\n",
    "task_def = \"{aws fargate task definition}\"\n",
    "subnet_id = \"{aws subnet id}\"\n",
    "security_group = \"{aws security group}\"\n",
    "fargate_cluster = \"{fargate cluster name}\"\n",
    "job_queue = \"{job queue}\"\n",
    "job_def = \"{job definition}\"\n",
    "model_storage = \"{model storage path}\"\n",
    "\n",
    "train_path1 = \"{train path 1}\"\n",
    "train_path2 = \"{train path 2}\"\n",
    "test_path = \"{test path}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create fargate and batch task builder object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "import task builder"
    ]
   },
   "outputs": [],
   "source": [
    "from integrate_ai_sdk.taskgroup.taskbuilder import aws as taskbuilder_aws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb = taskbuilder_aws.fargate(aws_credentials=aws_creds, cluster=fargate_cluster, task_definition=task_def)\n",
    "\n",
    "tb_batch = taskbuilder_aws.batch(aws_credentials=aws_creds, job_queue=job_queue, cpu_job_definition=job_def)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create task group to run the server and batch and start it\n",
    "If `ssm_token_key` is not specified, key name is going to be generated by `client`. You have to pass `client` for the system to obtain a session token and store it in SSM. If client is not passed, then the default token key defined in the task definition is going to be used to fetch a JWT token. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "start session task group"
    ]
   },
   "outputs": [],
   "source": [
    "from integrate_ai_sdk.taskgroup.base import SessionTaskGroup\n",
    "\n",
    "task_group_context = (\n",
    "    SessionTaskGroup(training_session)\n",
    "    .add_task(tb.fls(subnet_id, security_group, storage_path=model_storage, client=client))\n",
    "    .add_task(tb_batch.hfl(train_path=train_path1, test_path=test_path, vcpus=\"2\", memory=\"16384\", client=client))\n",
    "    .add_task(tb_batch.hfl(train_path=train_path2, test_path=test_path, vcpus=\"2\", memory=\"16384\", client=client))\n",
    "    .start()\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitor submitted jobs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# session available in group context after submission\n",
    "print(task_group_context.session.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# status of tasks submitted\n",
    "task_group_status = task_group_context.status()\n",
    "for task_status in task_group_status:\n",
    "    print(task_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use to monitor if a session has completed successfully or has failed\n",
    "# You can modify the time to wait as per your specific task\n",
    "task_group_context.wait(30)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Session Complete!\n",
    "Now you can view the training metrics and start making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "view session metrics"
    ]
   },
   "outputs": [],
   "source": [
    "training_session.metrics().as_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = training_session.metrics().plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trained model parameters are accessible from the completed session\n",
    "Model parameters can be retrieved using the model's state_dict method. These parameters can then be saved with torch.save()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "save model"
    ]
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "model = training_session.model().as_pytorch()\n",
    "\n",
    "save_state_dict_folder = \"./saved_models\"\n",
    "# PyTorch conventional file type\n",
    "file_name = f\"{training_session.id}.pt\"\n",
    "os.makedirs(save_state_dict_folder, exist_ok=True)\n",
    "saved_state_dict_path = os.path.join(save_state_dict_folder, file_name)\n",
    "\n",
    "with open(saved_state_dict_path, \"w\") as f:\n",
    "    torch.save(model.state_dict(), saved_state_dict_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the saved model\n",
    "To load a model saved previously, a model object needs to be initialized first. This can be done by directly importing one of the IAI-supported packages (e.g., FFNet) or using the model class defined in a custom package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "load model"
    ]
   },
   "outputs": [],
   "source": [
    "from integrate_ai_sdk.packages.GLM.model import GLM\n",
    "\n",
    "model = GLM(input_size=15, output_activation=\"sigmoid\")\n",
    "\n",
    "# use torch.load to unpickle the state_dict\n",
    "target_state_dict = torch.load(saved_state_dict_path)\n",
    "\n",
    "model.load_state_dict(target_state_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "test_data = pd.read_parquet(test_path)\n",
    "test_data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert test data to tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = torch.tensor(test_data[\"y\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor(\n",
    "    test_data[[\"x0\", \"x1\", \"x2\", \"x3\", \"x4\", \"x5\", \"x6\", \"x7\", \"x8\", \"x9\", \"x10\", \"x11\", \"x12\", \"x13\", \"x14\"]].values\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "predict"
    ]
   },
   "outputs": [],
   "source": [
    "preds = model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = preds.max(dim=1)[1]\n",
    "labels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "integrate_ai_sdk-L6kUa9f7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16 (default, Jan 18 2023, 11:05:05) \n[Clang 14.0.0 (clang-1400.0.29.202)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "9668bd68a45449a603c007a3ac0147bfe97ff582415f6f9325554aa5d85a2bfd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
