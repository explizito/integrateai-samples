{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# integrate.ai API Sample Notebook to run client on Azure Container Instances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This task group implementation is meant to be a POC for running tasks in ACI. Not for production use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set environment variables (or replace inline) with your IAI credentials\n",
    "### Generate and manage this token in the UI, in the Tokens page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "IAI_TOKEN = os.environ.get(\"IAI_TOKEN\")\n",
    "\n",
    "# These are credentials for the remote processes, service principal that has limited access\n",
    "# was previously created.\n",
    "IAI_SP = os.environ[\"IAI_SP\"]\n",
    "IAI_PW = os.environ[\"IAI_PW\"]\n",
    "IAI_TENANT = os.environ[\"IAI_TENANT\"]\n",
    "\n",
    "os.environ[\"IAI_AZURE_BLOB_STORAGE_ACCOUNT\"] = \"testronstorageaccount\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authenticate to the integrate.ai api client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from integrate_ai_sdk.api import connect\n",
    "\n",
    "client = connect(token=IAI_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample model config and data schema\n",
    "You can find the model config and data schema in the [integrate.ai end user tutorial](https://integrate-ai.gitbook.io/integrate.ai-user-documentation/tutorials/end-user-tutorials/model-training-with-a-sample-local-dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = {\n",
    "    \"experiment_name\": \"test_synthetic_tabular\",\n",
    "    \"experiment_description\": \"test_synthetic_tabular\",\n",
    "    \"strategy\": {\"name\": \"FedAvg\", \"params\": {}},\n",
    "    \"model\": {\"params\": {\"input_size\": 15, \"hidden_layer_sizes\": [6, 6, 6], \"output_size\": 2}},\n",
    "    \"balance_train_datasets\": False,\n",
    "    \"ml_task\": {\n",
    "        \"type\": \"classification\",\n",
    "        \"params\": {\n",
    "            \"loss_weights\": None,\n",
    "        },\n",
    "    },\n",
    "    \"optimizer\": {\"name\": \"SGD\", \"params\": {\"learning_rate\": 0.2, \"momentum\": 0.0}},\n",
    "    \"differential_privacy_params\": {\"epsilon\": 4, \"max_grad_norm\": 7},\n",
    "    \"save_best_model\": {\n",
    "        \"metric\": \"loss\",  # to disable this and save model from the last round, set to None\n",
    "        \"mode\": \"min\",\n",
    "    },\n",
    "    \"seed\": 23,  # for reproducibility\n",
    "}\n",
    "\n",
    "data_schema = {\n",
    "    \"predictors\": [\"x0\", \"x1\", \"x2\", \"x3\", \"x4\", \"x5\", \"x6\", \"x7\", \"x8\", \"x9\", \"x10\", \"x11\", \"x12\", \"x13\", \"x14\"],\n",
    "    \"target\": \"y\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Azure SessionTaskGroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from integrate_ai_sdk.taskgroup.taskbuilder import azure, local\n",
    "from integrate_ai_sdk.taskgroup.base import SessionTaskGroup\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "# important to use ProcessPoolExecutor to avoid deadlocks\n",
    "# max workers needs to be set to at least the same number of concurrent tasks,\n",
    "# in order to avoid deadlocks.\n",
    "executor = ProcessPoolExecutor(max_workers=10)\n",
    "\n",
    "local_tb = local.local_python(executor, client)\n",
    "\n",
    "tb = azure.aci(\n",
    "    subscription_id=\"21cb130d-da92-4bcc-ae6e-f18889c9a637\",\n",
    "    storage_account=\"testronstorageaccount\",\n",
    "    resource_group=\"test-ron-resource-group\",\n",
    "    image_repo=\"iaitestrepo.azurecr.io\",\n",
    "    server_image=\"edge/fl-server-internal:2.2.20\",  # TODO this should be fetched from gateway for default\n",
    "    client_image=\"edge/fl-client-internal:2.0.18-cpu\",\n",
    "    remote_service_principal=azure.ServicePrincipalCredential(id=IAI_SP, password=IAI_PW, tenant=IAI_TENANT),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# session available in group context after submission\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def wait_and_print(task_group_context):\n",
    "    max_count = 60\n",
    "    count = 0\n",
    "    while True:\n",
    "        print(datetime.now())\n",
    "        for task in task_group_context.contexts:\n",
    "            print(f\"{task.status()['info'].name}: {task.status()['info'].instance_view.state}\")\n",
    "        if task_group_context.wait(5):\n",
    "            break\n",
    "        if count >= max_count:\n",
    "            raise Exception(\"Waited too long!\")\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up autoreload in notebook (jupyter specific)\n",
    "\n",
    "This allows for code that's being developed in the python virtual env to be have modules autoreloaded on change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Specifying optional AWS Credentials, path to datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to your training and test data on S3\n",
    "data_dir = \"az://test-ron-blob/synthetic\"\n",
    "# data_dir = '~/Downloads/synthetic'\n",
    "storage_path = \"azure://test-ron-blob\"\n",
    "train_path1 = f\"{data_dir}/train_silo0.parquet\"\n",
    "train_path2 = f\"{data_dir}/train_silo1.parquet\"\n",
    "test_path = f\"{data_dir}/test.parquet\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and Run EDA Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_config = {\"dataset_one\": [], \"dataset_two\": []}\n",
    "\n",
    "eda_session = client.create_eda_session(\n",
    "    name=\"Testing notebook - EDA\",\n",
    "    description=\"I am testing EDA session creation through a notebook\",\n",
    "    data_config=dataset_config,\n",
    "    startup_mode=\"external\",\n",
    ").start()\n",
    "eda_session.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eda_task_group = (\n",
    "    SessionTaskGroup(eda_session)\n",
    "    .add_task(tb.fls(storage_path=storage_path))\n",
    "    .add_task(tb.eda(dataset_name=\"dataset_one\", dataset_path=train_path1))\n",
    "    .add_task(tb.eda(dataset_name=\"dataset_two\", dataset_path=train_path2))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eda_task_group_context = eda_task_group.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wait_and_print(eda_task_group_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(eda_task_group_context.contexts[0].logs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(eda_task_group_context.contexts[1].logs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(eda_task_group_context.contexts[2].logs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = eda_session.results()\n",
    "results.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Training Session\n",
    "\n",
    "The documentation for [creating a session](https://integrate-ai.gitbook.io/integrate.ai-user-documentation/tutorials/end-user-tutorials/model-training-with-a-sample-local-dataset#create-and-start-the-session) gives a bit more context into the parameters that are used during training session creation.<br />\n",
    "For this session we are going to be using two training clients and two rounds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_session = client.create_fl_session(\n",
    "    name=\"Testing notebook\",\n",
    "    description=\"I am testing session creation through a notebook\",\n",
    "    min_num_clients=2,\n",
    "    num_rounds=2,\n",
    "    package_name=\"iai_ffnet\",\n",
    "    model_config=model_config,\n",
    "    data_config=data_schema,\n",
    "    startup_mode=\"external\",\n",
    ").start()\n",
    "\n",
    "training_session.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create task_group with appropriate number of tasks\n",
    "#### Number of tasks added should match min_number of clients specified when creating the session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_group = (\n",
    "    SessionTaskGroup(training_session)\n",
    "    .add_task(tb.fls(storage_path=storage_path))\n",
    "    .add_task(tb.hfl(train_path=train_path1, test_path=test_path))\n",
    "    .add_task(tb.hfl(train_path=train_path2, test_path=test_path))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hfl_task_group_context = task_group.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitor submitted jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wait_and_print(hfl_task_group_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hfl_task_group_context.contexts[0].logs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hfl_task_group_context.contexts[1].logs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hfl_task_group_context.contexts[2].logs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_session.metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trained model parameters are accessible from the completed session\n",
    "\n",
    "Model parameters can be retrieved using the model's state_dict method. These parameters can then be saved with torch.save()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "model = training_session.model().as_pytorch()\n",
    "\n",
    "save_state_dict_folder = \"./saved_models\"\n",
    "# PyTorch conventional file type\n",
    "file_name = f\"{training_session.id}.pt\"\n",
    "os.makedirs(save_state_dict_folder, exist_ok=True)\n",
    "saved_state_dict_path = os.path.join(save_state_dict_folder, file_name)\n",
    "\n",
    "with open(saved_state_dict_path, \"w\") as f:\n",
    "    torch.save(model.state_dict(), saved_state_dict_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the saved model\n",
    "\n",
    "To load a model saved previously, a model object needs to be initialized first. This can be done by directly importing one of the IAI-supported packages (e.g., FFNet) or using the model class defined in a custom package. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from integrate_ai_sdk.packages.FFNet.nn_model import FFNet\n",
    "\n",
    "model = FFNet(input_size=15, output_size=2, hidden_layer_sizes=[6, 6, 6])\n",
    "\n",
    "# use torch.load to unpickle the state_dict\n",
    "target_state_dict = torch.load(saved_state_dict_path)\n",
    "\n",
    "model.load_state_dict(target_state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from integrate_ai_sdk.utils.util import get_pandas_read_storage_option\n",
    "\n",
    "test_data_path = f\"{data_dir}/test.parquet\"\n",
    "test_data = pd.read_parquet(test_data_path, storage_options=get_pandas_read_storage_option(test_data_path))\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert test data to tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = torch.tensor(test_data[\"y\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor(\n",
    "    test_data[[\"x0\", \"x1\", \"x2\", \"x3\", \"x4\", \"x5\", \"x6\", \"x7\", \"x8\", \"x9\", \"x10\", \"x11\", \"x12\", \"x13\", \"x14\"]].values\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = model(X).max(dim=1)[1]\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "dbc5519a256afcf5260ac2558501c187e408fe2a3845808743eddd307a69954f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
