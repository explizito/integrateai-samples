{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1cd37dfc",
   "metadata": {},
   "source": [
    "# integrate.ai HFL Gradient Boosting Methods Sample Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d905507a",
   "metadata": {},
   "source": [
    "## Set environment variables (or replace inline) with your IAI credentials\n",
    "### Generate and manage this token in the UI, in the Tokens page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99153ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "IAI_TOKEN = os.environ.get(\"IAI_TOKEN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93309c89",
   "metadata": {},
   "source": [
    "## Authenticate to the integrate.ai api client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88e6fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from integrate_ai_sdk.api import connect\n",
    "\n",
    "client = connect(token=\"IAI_TOKEN\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dbfb82e9",
   "metadata": {},
   "source": [
    "## Sample model config and data schema\n",
    "You can find the model config and data schema in the [HFL-GBM tutorial](https://integrate-ai.gitbook.io/integrate.ai-user-documentation/tutorials/hfl-gradient-boosted-models-hfl-gbm#review-the-sample-model-configuration)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a49c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = {\n",
    "    \"strategy\": {\"name\": \"HistGradientBoosting\", \"params\": {}},\n",
    "    \"model\": {\n",
    "        \"params\": {\n",
    "            \"max_depth\": 4,\n",
    "            \"learning_rate\": 0.05,\n",
    "            \"random_state\": 23,  # for reproducibility\n",
    "            \"max_bins\": 128,\n",
    "            \"sketch_relative_accuracy\": 0.001,\n",
    "        }\n",
    "    },\n",
    "    \"ml_task\": {\"type\": \"classification\", \"params\": {}},\n",
    "    \"save_best_model\": {\"metric\": None, \"mode\": \"min\"},\n",
    "}\n",
    "\n",
    "data_schema = {\n",
    "    \"predictors\": [\"x0\", \"x1\", \"x2\", \"x3\", \"x4\", \"x5\", \"x6\", \"x7\", \"x8\", \"x9\", \"x10\", \"x11\", \"x12\", \"x13\", \"x14\"],\n",
    "    \"target\": \"y\",\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ea791a89",
   "metadata": {},
   "source": [
    "## Create a Training Session\n",
    "\n",
    "The documentation for [creating a session](https://integrate-ai.gitbook.io/integrate.ai-user-documentation/tutorials/end-user-tutorials/model-training-with-a-sample-local-dataset#create-and-start-the-session) gives a bit more context into the parameters that are used during training session creation.<br />\n",
    "For this session we are going to be using two training clients and ten rounds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd261a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_session = client.create_fl_session(\n",
    "    name=\"HFL session testing GBM\",\n",
    "    description=\"I am testing GBM session creation through a notebook\",\n",
    "    min_num_clients=2,\n",
    "    num_rounds=10,\n",
    "    package_name=\"iai_gbm\",\n",
    "    model_config=model_config,\n",
    "    data_config=data_schema,\n",
    ").start()\n",
    "\n",
    "training_session.id"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "03d5dd84",
   "metadata": {},
   "source": [
    "## Start a training session using iai client\n",
    "Make sure that the sample data you [downloaded](#https://integrate-ai.gitbook.io/integrate.ai-user-documentation/tutorials/hfl-gradient-boosted-models-hfl-gbm#review-the-sample-model-configuration) is saved to your `~/Downloads` directory, otherwise update the `data_path` below to point to the sample data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f06db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "data_path = \"~/Downloads/synthetic\"\n",
    "\n",
    "client_1 = subprocess.Popen(\n",
    "    f\"iai client train --token {IAI_TOKEN} --session {training_session.id} --train-path {data_path}/train_silo0.parquet --test-path {data_path}/test.parquet --batch-size 1024 --client-name client-1 --remove-after-complete\",\n",
    "    shell=True,\n",
    "    stdout=subprocess.PIPE,\n",
    "    stderr=subprocess.PIPE,\n",
    ")\n",
    "\n",
    "client_2 = subprocess.Popen(\n",
    "    f\"iai client train --token {IAI_TOKEN} --session {training_session.id} --train-path {data_path}/train_silo1.parquet --test-path {data_path}/test.parquet --batch-size 1024 --client-name client-2 --remove-after-complete\",\n",
    "    shell=True,\n",
    "    stdout=subprocess.PIPE,\n",
    "    stderr=subprocess.PIPE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427b2509",
   "metadata": {},
   "source": [
    "## Poll for session status\n",
    "\n",
    "You can log whatever you would like about the session during this time. For now we are logging the current round and the session status. If you want to access the logs later you can use `iai client log` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8246c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "current_round = None\n",
    "current_status = None\n",
    "while client_1.poll() is None or client_2.poll() is None:\n",
    "    output1 = client_1.stdout.readline().decode(\"utf-8\").strip()\n",
    "    output2 = client_2.stdout.readline().decode(\"utf-8\").strip()\n",
    "    if output1:\n",
    "        print(\"silo1: \", output1)\n",
    "    if output2:\n",
    "        print(\"silo2: \", output2)\n",
    "\n",
    "    # poll for status and round\n",
    "    if current_status != training_session.status:\n",
    "        print(\"Session status: \", training_session.status)\n",
    "        current_status = training_session.status\n",
    "    if current_round != training_session.round and training_session.round > 0:\n",
    "        print(\"Session round: \", training_session.round)\n",
    "        current_round = training_session.round\n",
    "    time.sleep(1)\n",
    "\n",
    "output1, error1 = client_1.communicate()\n",
    "output2, error2 = client_2.communicate()\n",
    "\n",
    "print(\n",
    "    \"client_1 finished with return code: %d\\noutput: %s\\n  %s\"\n",
    "    % (client_1.returncode, output1.decode(\"utf-8\"), error1.decode(\"utf-8\"))\n",
    ")\n",
    "print(\n",
    "    \"client_2 finished with return code: %d\\noutput: %s\\n  %s\"\n",
    "    % (client_2.returncode, output2.decode(\"utf-8\"), error2.decode(\"utf-8\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68db15bc",
   "metadata": {},
   "source": [
    "## Session Complete!\n",
    "Now you can view the training metrics and start making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e7c863",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_session.metrics().as_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad387b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = training_session.metrics().plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a5c4e931",
   "metadata": {},
   "source": [
    "### Trained model parameters are accessible from the completed session\n",
    "\n",
    "Model parameters can be retrieved using the model's as_sklearn method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b8ab70",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = training_session.model().as_sklearn()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2a2e43",
   "metadata": {},
   "source": [
    "## Load test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d688478",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "test_data = pd.read_parquet(f\"{data_path}/test.parquet\")\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee99691d",
   "metadata": {},
   "source": [
    "## Convert test data to tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d79b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = test_data[\"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafd4791",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = test_data[[\"x0\", \"x1\", \"x2\", \"x3\", \"x4\", \"x5\", \"x6\", \"x7\", \"x8\", \"x9\", \"x10\", \"x11\", \"x12\", \"x13\", \"x14\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab04c097",
   "metadata": {},
   "source": [
    "## Run model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd4a232",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49f388b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "y_hat = model.predict_proba(X)\n",
    "roc_auc_score(Y, y_hat[:, 1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "f4908f7b5ba0ade04b74e4e2b06098d89c93ed996a8041e510753b482fc79320"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
