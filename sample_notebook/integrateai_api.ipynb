{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cd37dfc",
   "metadata": {},
   "source": [
    "# integrate.ai API Sample Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d905507a",
   "metadata": {},
   "source": [
    "## Set environment variables (or replace inline) with your IAI credentials\n",
    "### Generate and manage this token in the UI, in the Tokens page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99153ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "IAI_TOKEN = os.environ.get(\"IAI_TOKEN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93309c89",
   "metadata": {},
   "source": [
    "## Authenticate to the integrate.ai api client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88e6fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from integrate_ai_sdk.api import connect\n",
    "\n",
    "client = connect(token=IAI_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1691212b",
   "metadata": {},
   "source": [
    "## Create an EDA Session for exploring the datasets\n",
    "\n",
    "To create an EDA session, we specify a `dataset_config` dictionary indicating the columns to explore for each dataset. Here the empty list `[]` means to include all columns. The number of expected datasets will be inferred as the number of items in dataset_config (i.e., two). Alternatively, we can manually set it with the optional argument `num_datasets` in `client.create_eda_session()`\n",
    "\n",
    "For information more information on how to configure an EDA session from scratch, reference the documentation [here](https://integrate-ai.gitbook.io/integrate.ai-user-documentation/tutorials/exploratory-data-analysis-eda)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95960477",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_config = {\"dataset_one\": [], \"dataset_two\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb87626",
   "metadata": {},
   "outputs": [],
   "source": [
    "eda_session = client.create_eda_session(\n",
    "    name=\"Testing notebook - EDA\",\n",
    "    description=\"I am testing EDA session creation through a notebook\",\n",
    "    data_config=dataset_config,\n",
    ").start()\n",
    "\n",
    "eda_session.id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcb602a",
   "metadata": {},
   "source": [
    "## Start an EDA Session using IAI client\n",
    "Follow the documentation on directions for how to install the [integrate_ai](https://pypi.org/project/integrate-ai/) package and the [sample data](https://integrate-ai.gitbook.io/integrate.ai-user-documentation/tutorials/end-user-tutorials/model-training-with-a-sample-local-dataset#prerequisites).<br/>\n",
    "Unzip the sample data to your `~/Downloads` directory, otherwise update the `data_path` below to point to the sample data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be148d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "data_path = \"~/Downloads/synthetic\"\n",
    "\n",
    "dataset_1 = subprocess.Popen(\n",
    "    f\"iai client eda --token {IAI_TOKEN} --session {eda_session.id} --dataset-path {data_path}/train_silo0.parquet --dataset-name dataset_one --remove-after-complete\",\n",
    "    shell=True,\n",
    "    stdout=subprocess.PIPE,\n",
    "    stderr=subprocess.PIPE,\n",
    ")\n",
    "\n",
    "dataset_2 = subprocess.Popen(\n",
    "    f\"iai client eda --token {IAI_TOKEN} --session {eda_session.id} --dataset-path {data_path}/train_silo1.parquet --dataset-name dataset_two --remove-after-complete\",\n",
    "    shell=True,\n",
    "    stdout=subprocess.PIPE,\n",
    "    stderr=subprocess.PIPE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e71cff2",
   "metadata": {},
   "source": [
    "## Poll for session status\n",
    "\n",
    "You can log whatever you would like about the session during this time. For now we are just checking for session completion.If you want to access the logs later you can use `iai client log` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56bd7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "current_status = None\n",
    "while dataset_1.poll() is None or dataset_2.poll() is None:\n",
    "    output1 = dataset_1.stdout.readline().decode(\"utf-8\").strip()\n",
    "    output2 = dataset_2.stdout.readline().decode(\"utf-8\").strip()\n",
    "    if output1:\n",
    "        print(\"silo1: \", output1)\n",
    "    if output2:\n",
    "        print(\"silo2: \", output2)\n",
    "\n",
    "    # poll for status\n",
    "    if current_status != eda_session.status:\n",
    "        print(\"Session status: \", eda_session.status)\n",
    "        current_status = eda_session.status\n",
    "    time.sleep(1)\n",
    "\n",
    "output1, error1 = dataset_1.communicate()\n",
    "output2, error2 = dataset_2.communicate()\n",
    "\n",
    "print(\n",
    "    \"dataset_1 finished with return code: %d\\noutput: %s\\n  %s\"\n",
    "    % (dataset_1.returncode, output1.decode(\"utf-8\"), error1.decode(\"utf-8\"))\n",
    ")\n",
    "print(\n",
    "    \"dataset_2 finished with return code: %d\\noutput: %s\\n  %s\"\n",
    "    % (dataset_2.returncode, output2.decode(\"utf-8\"), error2.decode(\"utf-8\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb551f1",
   "metadata": {},
   "source": [
    "## EDA Session Complete!\n",
    "Now you can analyze the datasets.\n",
    "\n",
    "The results object is a dataset collection, which is comprised of multiple datasets that can be retrieved by name. \n",
    "\n",
    "Each dataset is comprised of columns, which can be retrieved by column name. \n",
    "\n",
    "The same base analysis functions can be performed at the collection, dataset, or column level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e097f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = eda_session.results()\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3d2e38",
   "metadata": {},
   "source": [
    "The .describe() method can be used to retrieve a standard set of descriptive statistics.\n",
    "\n",
    "In this example, columns `x10` to `x14` are categorical and no statistics outside of `count` will be computed for these columns.\n",
    "\n",
    "If a statistical function is invalid for a column (ex: mean requires a continuous column and `x10` is categorical) or the column from one dataset is not present in the other then the result will show as `NaN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b26ffe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b82e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"dataset_one\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262716af",
   "metadata": {},
   "source": [
    "For categorical columns, other statistics like `unique_count`, `mode`, and `uniques` can be used for further exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb03690",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"dataset_one\"][[\"x10\", \"x11\"]].uniques()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed79e64",
   "metadata": {},
   "source": [
    "Functions like `.mean()`, `.median()`, `.std()` can also be called individually. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f66be28",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"dataset_one\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc1cfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"dataset_one\"][\"x1\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0dcfff4",
   "metadata": {},
   "source": [
    "Histogram plots can be created using the `.plot_hist()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44eef6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_dataset_one_hist_plots = results[\"dataset_two\"].plot_hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e48b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_hist = results[\"dataset_two\"][\"x1\"].plot_hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfb82e9",
   "metadata": {},
   "source": [
    "## Sample model config and data schema\n",
    "You can find the model config and data schema in the [integrate.ai end user tutorial](https://integrate-ai.gitbook.io/integrate.ai-user-documentation/tutorials/end-user-tutorials/model-training-with-a-sample-local-dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a49c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = {\n",
    "    \"experiment_name\": \"test_synthetic_tabular\",\n",
    "    \"experiment_description\": \"test_synthetic_tabular\",\n",
    "    \"strategy\": {\"name\": \"FedAvg\", \"params\": {}},\n",
    "    \"model\": {\"params\": {\"input_size\": 15, \"hidden_layer_sizes\": [6, 6, 6], \"output_size\": 2}},\n",
    "    \"balance_train_datasets\": False,\n",
    "    \"ml_task\": {\n",
    "        \"type\": \"classification\",\n",
    "        \"params\": {\n",
    "            \"loss_weights\": None,\n",
    "        },\n",
    "    },\n",
    "    \"optimizer\": {\"name\": \"SGD\", \"params\": {\"learning_rate\": 0.2, \"momentum\": 0.0}},\n",
    "    \"differential_privacy_params\": {\"epsilon\": 4, \"max_grad_norm\": 7},\n",
    "    \"save_best_model\": {\n",
    "        \"metric\": \"loss\",  # to disable this and save model from the last round, set to None\n",
    "        \"mode\": \"min\",\n",
    "    },\n",
    "    \"seed\": 23,  # for reproducibility\n",
    "}\n",
    "\n",
    "data_schema = {\n",
    "    \"predictors\": [\"x0\", \"x1\", \"x2\", \"x3\", \"x4\", \"x5\", \"x6\", \"x7\", \"x8\", \"x9\", \"x10\", \"x11\", \"x12\", \"x13\", \"x14\"],\n",
    "    \"target\": \"y\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea791a89",
   "metadata": {},
   "source": [
    "## Create a Training Session\n",
    "\n",
    "The documentation for [creating a session](https://integrate-ai.gitbook.io/integrate.ai-user-documentation/tutorials/end-user-tutorials/model-training-with-a-sample-local-dataset#create-and-start-the-session) gives a bit more context into the parameters that are used during training session creation.<br />\n",
    "For this session we are going to be using two training clients and two rounds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd261a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_session = client.create_fl_session(\n",
    "    name=\"Testing notebook\",\n",
    "    description=\"I am testing session creation through a notebook\",\n",
    "    min_num_clients=2,\n",
    "    num_rounds=2,\n",
    "    package_name=\"iai_ffnet\",\n",
    "    model_config=model_config,\n",
    "    data_config=data_schema,\n",
    ").start()\n",
    "\n",
    "training_session.id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d5dd84",
   "metadata": {},
   "source": [
    "## Start a training session using iai client\n",
    "Make sure that the sample data you downloaded to [Start an EDA Session](#Start-an-EDA-Session-using-IAI-client) is saved to your `~/Downloads` directory, otherwise update the `data_path` below to point to the sample data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f06db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "data_path = \"~/Downloads/synthetic\"\n",
    "\n",
    "client_1 = subprocess.Popen(\n",
    "    f\"iai client train --token {IAI_TOKEN} --session {training_session.id} --train-path {data_path}/train_silo0.parquet --test-path {data_path}/test.parquet --batch-size 1024 --client-name client-1 --remove-after-complete\",\n",
    "    shell=True,\n",
    "    stdout=subprocess.PIPE,\n",
    "    stderr=subprocess.PIPE,\n",
    ")\n",
    "\n",
    "client_2 = subprocess.Popen(\n",
    "    f\"iai client train --token {IAI_TOKEN} --session {training_session.id} --train-path {data_path}/train_silo1.parquet --test-path {data_path}/test.parquet --batch-size 1024 --client-name client-2 --remove-after-complete\",\n",
    "    shell=True,\n",
    "    stdout=subprocess.PIPE,\n",
    "    stderr=subprocess.PIPE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427b2509",
   "metadata": {},
   "source": [
    "## Poll for session status\n",
    "\n",
    "You can log whatever you would like about the session during this time. For now we are logging the current round and the session status. If you want to access the logs later you can use `iai client log` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8246c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "current_round = None\n",
    "current_status = None\n",
    "while client_1.poll() is None or client_2.poll() is None:\n",
    "    output1 = client_1.stdout.readline().decode(\"utf-8\").strip()\n",
    "    output2 = client_2.stdout.readline().decode(\"utf-8\").strip()\n",
    "    if output1:\n",
    "        print(\"silo1: \", output1)\n",
    "    if output2:\n",
    "        print(\"silo2: \", output2)\n",
    "\n",
    "    # poll for status and round\n",
    "    if current_status != training_session.status:\n",
    "        print(\"Session status: \", training_session.status)\n",
    "        current_status = training_session.status\n",
    "    if current_round != training_session.round and training_session.round > 0:\n",
    "        print(\"Session round: \", training_session.round)\n",
    "        current_round = training_session.round\n",
    "    time.sleep(1)\n",
    "\n",
    "output1, error1 = client_1.communicate()\n",
    "output2, error2 = client_2.communicate()\n",
    "\n",
    "print(\n",
    "    \"client_1 finished with return code: %d\\noutput: %s\\n  %s\"\n",
    "    % (client_1.returncode, output1.decode(\"utf-8\"), error1.decode(\"utf-8\"))\n",
    ")\n",
    "print(\n",
    "    \"client_2 finished with return code: %d\\noutput: %s\\n  %s\"\n",
    "    % (client_2.returncode, output2.decode(\"utf-8\"), error2.decode(\"utf-8\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c19c7a",
   "metadata": {},
   "source": [
    "## Session Complete!\n",
    "Now you can view the training metrics and start making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e7c863",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_session.metrics().as_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad387b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = training_session.metrics().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c4e931",
   "metadata": {},
   "source": [
    "## Trained model parameters are accessible from the completed session\n",
    "\n",
    "Model parameters can be retrieved using the model's state_dict method. These parameters can then be saved with torch.save()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b8ab70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "model = training_session.model().as_pytorch()\n",
    "\n",
    "save_state_dict_folder = \"./saved_models\"\n",
    "# PyTorch conventional file type\n",
    "file_name = f\"{training_session.id}.pt\"\n",
    "os.makedirs(save_state_dict_folder, exist_ok=True)\n",
    "saved_state_dict_path = os.path.join(save_state_dict_folder, file_name)\n",
    "\n",
    "with open(saved_state_dict_path, \"w\") as f:\n",
    "    torch.save(model.state_dict(), saved_state_dict_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9cd5d3b",
   "metadata": {},
   "source": [
    "## Load the saved model\n",
    "\n",
    "To load a model saved previously, a model object needs to be initialized first. This can be done by directly importing one of the IAI-supported packages (e.g., FFNet) or using the model class defined in a custom package. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d26ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from integrate_ai_sdk.packages.FFNet.nn_model import FFNet\n",
    "\n",
    "model = FFNet(input_size=15, output_size=2, hidden_layer_sizes=[6, 6, 6])\n",
    "\n",
    "# use torch.load to unpickle the state_dict\n",
    "target_state_dict = torch.load(saved_state_dict_path)\n",
    "\n",
    "model.load_state_dict(target_state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2a2e43",
   "metadata": {},
   "source": [
    "## Load test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d688478",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "test_data = pd.read_parquet(f\"{data_path}/test.parquet\")\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee99691d",
   "metadata": {},
   "source": [
    "## Convert test data to tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d79b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = torch.tensor(test_data[\"y\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafd4791",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor(\n",
    "    test_data[[\"x0\", \"x1\", \"x2\", \"x3\", \"x4\", \"x5\", \"x6\", \"x7\", \"x8\", \"x9\", \"x10\", \"x11\", \"x12\", \"x13\", \"x14\"]].values\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab04c097",
   "metadata": {},
   "source": [
    "## Run model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd4a232",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3399b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = model(X).max(dim=1)[1]\n",
    "labels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "bcd9669e40d0fa5d5cf75eb48a81d6f10b6f058751eae776fd44da813ec48fcb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
