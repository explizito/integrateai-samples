{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# integrate.ai API Sample Notebook to run client on AWS Batch and AWS Fargate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set environment variables (or replace inline) with your IAI credentials\n",
    "### Generate and manage this token in the UI, in the Tokens page\n",
    "### Generate AWS session credentials or use the default profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "IAI_TOKEN =  os.environ.get(\"IAI_TOKEN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authenticate to the integrate.ai api client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "authenticate to client"
    ]
   },
   "outputs": [],
   "source": [
    "from integrate_ai_sdk.api import connect\n",
    "\n",
    "client = connect(token=IAI_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import required packaged to run on AWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from integrate_ai_sdk.taskgroup.taskbuilder import aws as taskbuilder_aws\n",
    "from integrate_ai_sdk.taskgroup.base import SessionTaskGroup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specifying path to datasets and batch job definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example data paths in s3\n",
    "train_path1 = \"s3://sample-data.integrate.ai/prl/prl_silo0.csv\"\n",
    "train_path2 = \"s3://sample-data.integrate.ai/prl/prl_silo1.csv\"\n",
    "test_path1 = \"s3://sample-data.integrate.ai/prl/prl_silo0.csv\"\n",
    "test_path2 = \"s3://sample-data.integrate.ai/prl/prl_silo1.csv\"\n",
    "\n",
    "# Specify the AWS parameters\n",
    "cluster = \"iai-server-ecs-cluster\"\n",
    "task_definition = \"iai-server-fargate-job\"\n",
    "model_storage = \"s3://sample-data.integrate.ai\"\n",
    "security_group = \"iai_server_security_group\"\n",
    "subnet_id = \"subnet-id\"  # Public subnet (routed via IGW)\n",
    "job_queue = \"iai-client-batch-job-queue\"\n",
    "job_def = \"iai-client-batch-job\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specifying optional AWS Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your AWS Credentials if you are generating temporary ones, else use the default profile credentials\n",
    "aws_creds = {\n",
    "    'ACCESS_KEY': os.environ.get(\"AWS_ACCESS_KEY_ID\"),\n",
    "    'SECRET_KEY': os.environ.get(\"AWS_SECRET_ACCESS_KEY\"),\n",
    "    'SESSION_TOKEN': os.environ.get(\"AWS_SESSION_TOKEN\"),\n",
    "    'REGION': os.environ.get(\"AWS_REGION\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create task builder object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_server = taskbuilder_aws.fargate(\n",
    "    cluster=cluster,\n",
    "    task_definition=task_definition)\n",
    "\n",
    "tb = taskbuilder_aws.batch( \n",
    "    job_queue=job_queue,\n",
    "    aws_credentials=aws_creds,\n",
    "    cpu_job_definition=job_def)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample PRL Data Config\n",
    "\n",
    "For this session, two clients are going to be providing data. Client 1 and client 2 are naming their clients client_1 and client_2 respectively. Their datasets will be linked by the \"id\" column in any provided datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prl_data_config = {\n",
    "    \"clients\": {\n",
    "        \"passive_client\": {\"id_columns\": [\"id\"]},\n",
    "        \"active_client\": {\"id_columns\": [\"id\"]},\n",
    "    }\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a PRL Session for linking the datasets\n",
    "\n",
    "To create a PRL session, specify a `dataset_config` dictionary indicating the client names and columns to use as identifiers to link the datasets to each other. The number of expected clients will be inferred as the number of items in dataset_config (i.e., two). These client names are referenced for the compute on the PRL session and for any sessions that use the PRL session downstream.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prl_session = client.create_prl_session(\n",
    "    name=\"Testing notebook - PRL\",\n",
    "    description=\"I am testing PRL session creation through a notebook\",\n",
    "    data_config=prl_data_config,\n",
    ").start()\n",
    "\n",
    "prl_session.id"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create task_group with appropriate number of tasks\n",
    "#### Number of tasks added should match the number of clients specified in the data config when creating the session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "start batch clients"
    ]
   },
   "outputs": [],
   "source": [
    "task_group_context = SessionTaskGroup(prl_session)\\\n",
    "        .add_task(task_server.fls(subnet_id, security_group, storage_path=model_storage, client=client))\\\n",
    "        .add_task(tb.prl(train_path=train_path1, test_path=test_path1, vcpus='2', memory='16384', client=client, client_name=\"passive_client\"))\\\n",
    "        .add_task(tb.prl(train_path=train_path2, test_path=test_path2, vcpus='2', memory='16384', client=client, client_name=\"active_client\")).start()     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitor submitted jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# session available in group context after submission\n",
    "print(task_group_context.session.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# status of tasks submitted\n",
    "task_group_status = task_group_context.status()\n",
    "for task_status in task_group_status:\n",
    "    print(task_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use to monitor if a session has completed successfully or has failed\n",
    "# You can modify the time to wait as per your specific task\n",
    "task_group_context.wait(300)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PRL Session Complete!\n",
    "Now you can view the overlap stats for the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "view session metrics"
    ]
   },
   "outputs": [],
   "source": [
    "prl_session.metrics().as_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a VFL Training Session\n",
    "To create a VFL train session, specify the `prl_session_id` indicating the session above used to link the datasets together. The `vfl_mode` needs to be set to `'train'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = {\n",
    "    \"strategy\": {\"name\": \"SplitNN\", \"params\": {}},\n",
    "    \"model\": {\n",
    "        \"feature_models\": {\n",
    "            \"passive_client\": {\"params\": {\"input_size\": 7, \"hidden_layer_sizes\": [6], \"output_size\": 5}},\n",
    "            \"active_client\": {\"params\": {\"input_size\": 8, \"hidden_layer_sizes\": [6], \"output_size\": 5}},\n",
    "        },\n",
    "        \"label_model\": {\"params\": {\"hidden_layer_sizes\": [5], \"output_size\": 2}},\n",
    "    },\n",
    "    \"ml_task\": {\n",
    "        \"type\": \"classification\",\n",
    "        \"params\": {\n",
    "            \"loss_weights\": None,\n",
    "        },\n",
    "    },\n",
    "    \"optimizer\": {\"name\": \"SGD\", \"params\": {\"learning_rate\": 0.2, \"momentum\": 0.0}},\n",
    "    \"seed\": 23,  # for reproducibility\n",
    "}\n",
    "\n",
    "\n",
    "data_config = {\n",
    "        \"passive_client\": {\n",
    "            \"label_client\": False,\n",
    "            \"predictors\": [\"x1\", \"x3\", \"x5\", \"x7\", \"x9\", \"x11\", \"x13\"],\n",
    "            \"target\": None,\n",
    "        },\n",
    "        \"active_client\": {\n",
    "            \"label_client\": True,\n",
    "            \"predictors\": [\"x0\", \"x2\", \"x4\", \"x6\", \"x8\", \"x10\", \"x12\", \"x14\"],\n",
    "            \"target\": \"y\",\n",
    "        },\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vfl_train_session = client.create_vfl_session(\n",
    "    name=\"Testing notebook - VFL Train\",\n",
    "    description=\"I am testing VFL Train session creation through a notebook\",\n",
    "    prl_session_id=prl_session.id,\n",
    "    vfl_mode='train',\n",
    "    min_num_clients=2,\n",
    "    num_rounds=5,\n",
    "    package_name=\"iai_ffnet\",\n",
    "    data_config=data_config,\n",
    "    model_config=model_config\n",
    ").start()\n",
    "\n",
    "vfl_train_session.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create VFL task_group with appropriate number of tasks\n",
    "#### Number of tasks added should match the number of clients specified in the data config when creating the session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vfl_task_group_context = SessionTaskGroup(vfl_train_session)\\\n",
    "        .add_task(task_server.fls(subnet_id, security_group, storage_path=model_storage, client=client))\\\n",
    "        .add_task(tb.vfl_train(train_path=train_path1, test_path=test_path1, vcpus='2', memory='16384', batch_size=1024, storage_path=model_storage, client=client, client_name=\"passive_client\"))\\\n",
    "        .add_task(tb.vfl_train(train_path=train_path2, test_path=test_path2, vcpus='2', memory='16384', batch_size=1024, storage_path=model_storage, client=client, client_name=\"active_client\")).start()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitor submitted jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# session available in group context after submission\n",
    "print(vfl_task_group_context.session.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# status of tasks submitted\n",
    "vfl_task_group_status = vfl_task_group_context.status()\n",
    "for task_status in vfl_task_group_status:\n",
    "    print(task_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vfl_task_group_context.wait(300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session Complete!\n",
    "Now you can view the vfl training metrics and start making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vfl_train_session.metrics().as_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = vfl_train_session.metrics().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a Prediction on the trained VFL Model\n",
    "### Create a VFL Prediction Session\n",
    "To create a VFL predict session, specify the `prl_session_id` indicating the session above used to link the datasets together. You also need the `training_id` of the above VFL train session.The `vfl_mode` needs to be set to `'predict'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vfl_predict_session = client.create_vfl_session(\n",
    "    name=\"Testing notebook - VFL Predict\",\n",
    "    description=\"I am testing VFL Predict session creation through a notebook\",\n",
    "    prl_session_id=prl_session.id,\n",
    "    training_session_id=vfl_train_session.id,\n",
    "    vfl_mode='predict',\n",
    "    data_config=data_config\n",
    ").start()\n",
    "\n",
    "vfl_predict_session.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify the full path to store your predictions including file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_predictions_storage_path=\"{full path of predictions file name}\"\n",
    "vfl_predict_task_group_context = SessionTaskGroup(vfl_predict_session)\\\n",
    "        .add_task(task_server.fls(subnet_id, security_group, storage_path=model_storage, client=client))\\\n",
    "        .add_task(tb.vfl_predict(client_name='active_client', dataset_path=test_path2, vcpus='2', memory='16384', batch_size=1024, storage_path=active_predictions_storage_path, client=client, raw_output=True))\\\n",
    "        .add_task(tb.vfl_predict(client_name='passive_client', dataset_path=test_path1, vcpus='2', memory='16384', batch_size=1024, storage_path=\"None\", client=client, raw_output=True)).start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitor submitted jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# session available in group context after submission\n",
    "print(vfl_predict_task_group_context.session.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# status of tasks submitted\n",
    "vfl_predict_task_group_status = vfl_predict_task_group_context.status()\n",
    "for task_status in vfl_predict_task_group_status:\n",
    "    print(task_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vfl_predict_task_group_context.wait(300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session Complete!\n",
    "Now you can view the vfl predictions and evaluate the performance as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_pred = pd.read_csv(active_predictions_storage_path)\n",
    "df_pred.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 ('integrate_ai_sdk-f9m4pwHO')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "952eef625ffef3c4b079b595e54ecfb33b2e14083a357459118caf861a3f97ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
