{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# integrate.ai API Sample Notebook to run client on Local Python VirtualEnv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This task group implementation is meant to facilitate development - not to be used in a production setting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set environment variables (or replace inline) with your IAI credentials\n",
    "### Generate and manage this token in the UI, in the Tokens page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "IAI_TOKEN = os.environ.get(\"IAI_TOKEN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authenticate to the integrate.ai api client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from integrate_ai_sdk.api import connect\n",
    "\n",
    "client = connect(token=IAI_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample model config and data schema\n",
    "You can find the model config and data schema in the [integrate.ai end user tutorial](https://integrate-ai.gitbook.io/integrate.ai-user-documentation/tutorials/end-user-tutorials/model-training-with-a-sample-local-dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = {\n",
    "    \"experiment_name\": \"test_synthetic_tabular\",\n",
    "    \"experiment_description\": \"test_synthetic_tabular\",\n",
    "    \"strategy\": {\"name\": \"FedAvg\", \"params\": {}},\n",
    "    \"model\": {\"params\": {\"input_size\": 15, \"hidden_layer_sizes\": [6, 6, 6], \"output_size\": 2}},\n",
    "    \"balance_train_datasets\": False,\n",
    "    \"ml_task\": {\n",
    "        \"type\": \"classification\",\n",
    "        \"params\": {\n",
    "            \"loss_weights\": None,\n",
    "        },\n",
    "    },\n",
    "    \"optimizer\": {\"name\": \"SGD\", \"params\": {\"learning_rate\": 0.2, \"momentum\": 0.0}},\n",
    "    \"differential_privacy_params\": {\"epsilon\": 4, \"max_grad_norm\": 7},\n",
    "    \"save_best_model\": {\n",
    "        \"metric\": \"loss\",  # to disable this and save model from the last round, set to None\n",
    "        \"mode\": \"min\",\n",
    "    },\n",
    "    \"seed\": 23,  # for reproducibility\n",
    "}\n",
    "\n",
    "data_schema = {\n",
    "    \"predictors\": [\"x0\", \"x1\", \"x2\", \"x3\", \"x4\", \"x5\", \"x6\", \"x7\", \"x8\", \"x9\", \"x10\", \"x11\", \"x12\", \"x13\", \"x14\"],\n",
    "    \"target\": \"y\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Local Python Environment SessionTaskGroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from integrate_ai_sdk.taskgroup.taskbuilder import local\n",
    "from integrate_ai_sdk.taskgroup.base import SessionTaskGroup\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "# important to use ProcessPoolExecutor to avoid deadlocks\n",
    "# max workers needs to be set to at least the same number of concurrent tasks,\n",
    "# in order to avoid deadlocks.\n",
    "executor = ProcessPoolExecutor(max_workers=10)\n",
    "\n",
    "tb = local.local_python(executor, client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up autoreload in notebook (jupyter specific)\n",
    "\n",
    "This allows for code that's being developed in the python virtual env to be have modules autoreloaded on change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Specifying optional AWS Credentials, path to datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to your training and test data on S3\n",
    "data_dir = \"~/Downloads/synthetic\"\n",
    "storage_path = \"s3://devel.integrate.ai\"\n",
    "train_path1 = f\"{data_dir}/train_silo0.parquet\"\n",
    "train_path2 = f\"{data_dir}/train_silo1.parquet\"\n",
    "test_path = f\"{data_dir}/test.parquet\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and Run EDA Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_config = {\"dataset_one\": [], \"dataset_two\": []}\n",
    "\n",
    "eda_session = client.create_eda_session(\n",
    "    name=\"Testing notebook - EDA\",\n",
    "    description=\"I am testing EDA session creation through a notebook\",\n",
    "    data_config=dataset_config,\n",
    "    startup_mode=\"external\",\n",
    ").start()\n",
    "eda_session.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eda_task_group = (\n",
    "    SessionTaskGroup(eda_session)\n",
    "    .add_task(tb.fls(storage_path=storage_path))\n",
    "    .add_task(tb.eda(dataset_name=\"dataset_one\", dataset_path=train_path1))\n",
    "    .add_task(tb.eda(dataset_name=\"dataset_two\", dataset_path=train_path2))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eda_task_group_context = eda_task_group.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eda_task_group_context.wait(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = eda_session.results()\n",
    "results.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Training Session\n",
    "\n",
    "The documentation for [creating a session](https://integrate-ai.gitbook.io/integrate.ai-user-documentation/tutorials/end-user-tutorials/model-training-with-a-sample-local-dataset#create-and-start-the-session) gives a bit more context into the parameters that are used during training session creation.<br />\n",
    "For this session we are going to be using two training clients and two rounds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_session = client.create_fl_session(\n",
    "    name=\"Testing notebook\",\n",
    "    description=\"I am testing session creation through a notebook\",\n",
    "    min_num_clients=2,\n",
    "    num_rounds=2,\n",
    "    package_name=\"iai_ffnet\",\n",
    "    model_config=model_config,\n",
    "    data_config=data_schema,\n",
    "    startup_mode=\"external\",\n",
    ").start()\n",
    "\n",
    "training_session.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create task_group with appropriate number of tasks\n",
    "#### Number of tasks added should match min_number of clients specified when creating the session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_group = (\n",
    "    SessionTaskGroup(training_session)\n",
    "    .add_task(tb.fls(storage_path=storage_path))\n",
    "    .add_task(tb.hfl(train_path=train_path1, test_path=test_path))\n",
    "    .add_task(tb.hfl(train_path=train_path2, test_path=test_path))\n",
    ")\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_group_context = task_group.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitor submitted jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# session available in group context after submission\n",
    "print(task_group_context.contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# status of tasks submitted\n",
    "for task in task_group_context.contexts:\n",
    "    print(f\"{task.future} {task.status()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use to monitor if a session has completed successfully or has failed\n",
    "# You can modify the time to wait as per your specific task\n",
    "task_group_context.wait(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_session.metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "dbc5519a256afcf5260ac2558501c187e408fe2a3845808743eddd307a69954f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
